{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from env import DroneEnv\n",
    "from BC import BC, BCAgent\n",
    "from PPO import PPO\n",
    "from PPO import RolloutBuffer\n",
    "from Trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = DroneEnv()\n",
    "state_shape = env.observation_space.shape\n",
    "action_shape = env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = PPO(\n",
    "    state_shape=env.observation_space.shape,\n",
    "    action_shape=env.action_space.shape,\n",
    "    seed=123,\n",
    "    env = env,\n",
    "    rollout_length=512,\n",
    "    batch_size=512,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    env=env,\n",
    "    algo=ppo,\n",
    "    seed=123,\n",
    "    num_steps= 100000,\n",
    "    eval_interval=1000,\n",
    "    num_eval_episodes=10,\n",
    "    max_episode_steps= 30,\n",
    "    save_dir = \"/save_dir/ppo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_weights(50000)\n",
    "trainer.save_weights(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模倣学習 + PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(env, num_episodes=500, max_episode_steps=500):\n",
    "    data = []\n",
    "    for _ in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        timestep = 0\n",
    "        episode_data = []\n",
    "        while not done and timestep < max_episode_steps:\n",
    "            action = env.action_space.sample()\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            # 目標物との距離を計算\n",
    "            target_distance = np.linalg.norm(env.target_position - env.drone_position)\n",
    "\n",
    "            # 目標物との距離が小さくなる方向に進んだ場合のみデータを保存\n",
    "            if target_distance < np.linalg.norm(env.target_position - state[:3]):\n",
    "                episode_data.append((state, action, reward, next_state, done))\n",
    "\n",
    "            state = next_state\n",
    "            timestep += 1\n",
    "\n",
    "        data.extend(episode_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DroneEnv()\n",
    "\n",
    "# データ収集\n",
    "data = collect_data(env, num_episodes=30000, max_episode_steps=200)\n",
    "\n",
    "buffer_exp = RolloutBuffer(buffer_size=len(data), state_shape=env.observation_space.shape, action_shape=env.action_space.shape)\n",
    "for state, action, reward, next_state, done in data:\n",
    "    buffer_exp.append(state, action, reward, done, 0)\n",
    "\n",
    "\n",
    "bc = BC(buffer_exp, \n",
    "        env.observation_space.shape, \n",
    "        env.action_space.shape, \n",
    "        seed=123, \n",
    "        batch_size=512)\n",
    "\n",
    "\n",
    "trainer = Trainer(env=env,\n",
    "                  algo=bc,\n",
    "                  seed=123,\n",
    "                  num_steps=30000,\n",
    "                  eval_interval=100,\n",
    "                  num_eval_episodes=10,\n",
    "                  max_episode_steps= 30,\n",
    "                  save_dir = \"/save_dir/BC\"\n",
    "                  )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エラー起こりますが問題ないです。\n",
    "trainer.save_weights(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = PPO(\n",
    "    state_shape=env.observation_space.shape,\n",
    "    action_shape=env.action_space.shape,\n",
    "    seed=123,\n",
    "    env = env,\n",
    "    rollout_length=512,\n",
    "    batch_size=512,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 重みをロードする\n",
    "ppo.actor.load_state_dict(torch.load('/save_dir/BC/actor_30000.pth'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    env=env,\n",
    "    algo=ppo,\n",
    "    seed=123,\n",
    "    num_steps= 50000,\n",
    "    eval_interval=1000,\n",
    "    num_eval_episodes=10,\n",
    "    max_episode_steps= 30,\n",
    "    save_dir = \"/save_dir/ppo_bc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_weights(50000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
